import os
import argparse
import torch
import tqdm
import json
import pandas as pd
import numpy as np
from torch.utils.data import DataLoader
from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score
from torch.optim import AdamW
from torch.nn import CrossEntropyLoss
import torch.nn.functional as F

# å¼•å…¥ä¿®æ”¹åçš„æ¨¡å— (ç¡®ä¿ mymodels é‡Œæœ‰ä½ æœ€æ–°çš„æ¨¡å‹å®šä¹‰)
from my_datautils import FakeNews_Dataset, FewShotSampler_weibo, FewShotSampler_fakenewsnet
from mymodels import CMA_Model  # æˆ–è€… CMA_Model_With_ACFC
from cn_clip.clip import load_from_name

device = "cuda" if torch.cuda.is_available() else "cpu"


def set_seeds(seed: int = 42):
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    np.random.seed(seed)


def save_results(args, history, best_preds, save_dir):
    """
    ä¿å­˜æ‰€æœ‰è®ºæ–‡éœ€è¦çš„å®éªŒç»“æœ
    """
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    # 1. ä¿å­˜é…ç½®å‚æ•° (Config)
    with open(os.path.join(save_dir, "config.json"), 'w') as f:
        json.dump(vars(args), f, indent=4)

    # 2. ä¿å­˜è®­ç»ƒæ—¥å¿— (ç”¨äºç”»æŠ˜çº¿å›¾: Epoch vs Loss/Acc/F1)
    with open(os.path.join(save_dir, "training_log.json"), 'w') as f:
        json.dump(history, f, indent=4)

    # 3. ä¿å­˜æœ€ä½³æ¨¡å‹çš„è¯¦ç»†é¢„æµ‹ç»“æœ (ç”¨äºç”»æ··æ·†çŸ©é˜µã€ROCæ›²çº¿ã€Caseåˆ†æ)
    # best_preds åŒ…å«: [true_label, pred_label, prob_class_0, prob_class_1]
    df_preds = pd.DataFrame(best_preds)
    df_preds.to_csv(os.path.join(save_dir, "best_predictions.csv"), index=False)

    # 4. ç”Ÿæˆå¹¶ä¿å­˜æœ€ä½³æ¨¡å‹çš„è¯¦ç»†è¯„ä¼°æŠ¥å‘Š (ç”¨äºè®ºæ–‡è¡¨æ ¼)
    y_true = df_preds['label'].values
    y_pred = df_preds['pred'].values

    # è®¡ç®—æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_true, y_pred)
    tn, fp, fn, tp = cm.ravel()

    # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    report = classification_report(y_true, y_pred, digits=4, output_dict=True)

    summary = {
        "Confusion Matrix": {"TN": int(tn), "FP": int(fp), "FN": int(fn), "TP": int(tp)},
        "Accuracy": accuracy_score(y_true, y_pred),
        "Macro F1": f1_score(y_true, y_pred, average='macro'),
        "Weighted F1": f1_score(y_true, y_pred, average='weighted'),
        "Detailed Report": report
    }

    with open(os.path.join(save_dir, "best_metrics_summary.json"), 'w') as f:
        json.dump(summary, f, indent=4)

    print(f"âœ… Results saved to {save_dir}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--dataset_name", type=str, default="weibo")
    parser.add_argument("--train_csv", type=str, required=True)
    parser.add_argument("--test_csv", type=str, required=True)
    parser.add_argument("--img_path", type=str, required=True)
    parser.add_argument("--shot", type=int, default=2)  # [cite: 168]
    parser.add_argument("--save_path", type=str, default="./checkpoints")
    args = parser.parse_args()

    set_seeds(args.seed)

    # å®šä¹‰ç»“æœä¿å­˜ç›®å½• (åŒºåˆ† Dataset, Shot, Seed)
    exp_name = f"{args.dataset_name}_{args.shot}shot_seed{args.seed}"
    result_dir = os.path.join("./paper_results", exp_name)  # ç»“æœç»Ÿä¸€ä¿å­˜åœ¨ paper_results æ–‡ä»¶å¤¹

    print(f"ğŸš€ Experiment: {exp_name}")
    print("Loading Chinese CLIP (Frozen)...")

    clip_model, preprocess = load_from_name("ViT-B-16", device=device)
    clip_model.eval()
    for param in clip_model.parameters():
        param.requires_grad = False  # å†»ç»“ CLIP

    # æ•°æ®é›†å‡†å¤‡
    train_dataset = FakeNews_Dataset(clip_model, preprocess, args.train_csv, args.img_path, args.dataset_name)
    test_dataset = FakeNews_Dataset(clip_model, preprocess, args.test_csv, args.img_path, args.dataset_name)

    # Few-shot é‡‡æ ·
    if args.dataset_name == 'ad':
        train_sampler = FewShotSampler_weibo(train_dataset, args.shot, args.seed)
        train_dataset = train_sampler.get_train_dataset()
    else:
        train_sampler = FewShotSampler_fakenewsnet(train_dataset, args.shot, args.seed)
        train_dataset, _ = train_sampler.get_train_val_datasets()

    print(f"Train Set Size: {len(train_dataset)}")
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

    # åˆå§‹åŒ–æ¨¡å‹ (è¿™é‡Œå¦‚æœç”¨äº† ACFCï¼Œè®°å¾—æŠŠ CMA_Model æ¢æˆ CMA_Model_With_ACFC)
    cma_model = CMA_Model(feature_dim=512, num_classes=2).to(device)

    optimizer = AdamW(cma_model.parameters(), lr=1e-3, weight_decay=1e-2)
    loss_func = CrossEntropyLoss()

    best_acc = 0.0
    best_preds_data = []  # ç”¨äºä¿å­˜æœ€ä½³ Epoch çš„é¢„æµ‹è¯¦æƒ…

    # ç”¨äºè®°å½•è®­ç»ƒè¿‡ç¨‹
    history = {
        "epoch": [],
        "loss": [],
        "train_acc": [],
        "test_acc": [],
        "test_f1_macro": [],
        "test_f1_weighted": []
    }

    EPOCH = 20  # [cite: 165]

    for epoch in range(EPOCH):
        cma_model.train()
        total_loss = 0
        correct = 0
        total = 0

        for txt, img, label, mask in train_loader:
            txt, img, label, mask = txt.to(device), img.to(device), label.to(device), mask.to(device)

            # è·å–ç»´åº¦: Batch, Slices, Channels, H, W
            B, S, C, H, W = img.shape

            # --- [å…³é”®æ­¥éª¤] ç‰¹å¾æå– ---
            with torch.no_grad():
                # 1. å±•å¹³ B å’Œ S ç»´åº¦ï¼Œè®© CLIP ä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰åˆ‡ç‰‡
                img_flat = img.view(B * S, C, H, W)  # [B*S, 3, 224, 224]
                txt_flat = txt.view(B * S, -1)  # [B*S, 77]

                # 2. CLIP æå–
                img_feat_flat = clip_model.encode_image(img_flat)  # [B*S, 512]
                txt_feat_flat = clip_model.encode_text(txt_flat)  # [B*S, 512]

                # 3. å˜å› [Batch, Slices, 512]
                img_feat = img_feat_flat.view(B, S, -1)
                txt_feat = txt_feat_flat.view(B, S, -1)

            # --- å‰å‘ä¼ æ’­ ---
            optimizer.zero_grad()

            # ä¼ å…¥ mask
            logits = cma_model(txt_feat.float(), img_feat.float(), mask)

            loss = loss_func(logits, label)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            preds = torch.argmax(logits, dim=1)
            correct += (preds == label).sum().item()
            total += label.size(0)

        train_acc = correct / total if total > 0 else 0
        avg_loss = total_loss / len(train_loader)

        print(f"Epoch {epoch + 1} | Loss: {avg_loss:.4f} | Train Acc: {train_acc:.2f}")

        # --- Evaluation ---
        cma_model.eval()
        test_labels = []
        pred_labels = []
        pred_probs_list = []  # ä¿å­˜æ¦‚ç‡ç”¨äº ROC æ›²çº¿

        with torch.no_grad():
            for txt, img, label, mask in tqdm.tqdm(test_loader, desc="Testing"):
                txt, img, label, mask = txt.to(device), img.to(device), label.to(device), mask.to(device)

                # ... (ç‰¹å¾æå–å’Œ View å˜æ¢ä»£ç ä¿æŒä¸å˜) ...
                B, S, C, H, W = img.shape
                img_flat = img.view(B * S, C, H, W)
                txt_flat = txt.view(B * S, -1)
                img_feat_flat = clip_model.encode_image(img_flat)
                txt_feat_flat = clip_model.encode_text(txt_flat)
                img_feat = img_feat_flat.view(B, S, -1)
                txt_feat = txt_feat_flat.view(B, S, -1)

                # å‰å‘ä¼ æ’­
                logits = cma_model(txt_feat.float(), img_feat.float(), mask)

                # è®¡ç®—æ¦‚ç‡
                probs = F.softmax(logits, dim=1)
                preds = torch.argmax(probs, dim=-1)

                # ã€æ ¸å¿ƒä¿®æ”¹ç‚¹ã€‘ä½¿ç”¨ append è€Œä¸æ˜¯ extendï¼Œé¿å…ç»´åº¦æ··ä¹±
                test_labels.extend(label.cpu().numpy())
                pred_labels.extend(preds.cpu().numpy())
                pred_probs_list.append(probs.cpu().numpy())  # æŠŠæ•´ä¸ª Batch çš„æ¦‚ç‡çŸ©é˜µå­˜è¿›å»

                # ã€æ ¸å¿ƒä¿®æ”¹ç‚¹ã€‘åœ¨å¾ªç¯å¤–è¿›è¡Œæ‹¼æ¥
                # å°† list of arrays [ (64,2), (64,2), (10,2) ] -> big array (138, 2)
            if len(pred_probs_list) > 0:
                probs_np = np.concatenate(pred_probs_list, axis=0)
            else:
                probs_np = np.array([])

        # è®¡ç®—å„ç±»æŒ‡æ ‡
        curr_acc = accuracy_score(test_labels, pred_labels)
        macro_f1 = f1_score(test_labels, pred_labels, average='macro')
        weighted_f1 = f1_score(test_labels, pred_labels, average='weighted')

        # æ›´æ–°æ—¥å¿—
        history["epoch"].append(epoch + 1)
        history["loss"].append(avg_loss)
        history["train_acc"].append(train_acc)
        history["test_acc"].append(curr_acc)
        history["test_f1_macro"].append(macro_f1)
        history["test_f1_weighted"].append(weighted_f1)

        print(f"Test Accuracy: {curr_acc:.4f} | Macro F1: {macro_f1:.4f}")

        # å¦‚æœå‘ç°æ›´å¥½çš„æ¨¡å‹
        if curr_acc > best_acc:
            best_acc = curr_acc
            print(f"New Best Accuracy: {best_acc:.4f}, Saving model & metrics...")

            if not os.path.exists(args.save_path):
                os.makedirs(args.save_path)
            torch.save(cma_model.state_dict(), os.path.join(args.save_path, f"best_model_seed{args.seed}.pt"))

            # 2. ç¼“å­˜é¢„æµ‹æ•°æ®
            # æ­¤æ—¶ probs_np å·²ç»æ˜¯æ‹¼æ¥å¥½çš„ (N, 2) æ•°ç»„äº†ï¼Œå¯ä»¥ç›´æ¥åˆ‡ç‰‡
            best_preds_data = {
                "label": test_labels,
                "pred": pred_labels,
                "prob_0": probs_np[:, 0],  # çœŸå®æ–°é—»æ¦‚ç‡
                "prob_1": probs_np[:, 1]  # è™šå‡æ–°é—»æ¦‚ç‡
            }

    print(f"Final Best Accuracy: {best_acc}")

    # è®­ç»ƒç»“æŸåï¼Œç»Ÿä¸€ä¿å­˜æ‰€æœ‰æ–‡ä»¶åˆ° result_dir
    save_results(args, history, best_preds_data, result_dir)